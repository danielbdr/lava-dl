{"results": [["pycodestyle", "E121", 38, 12, "continuation line under-indented for hanging indent", "            }\n"], ["pycodestyle", "E121", 42, 12, "continuation line under-indented for hanging indent", "            }\n"], ["pycodestyle", "E121", 46, 12, "continuation line under-indented for hanging indent", "            }\n"], ["pycodestyle", "E121", 64, 12, "continuation line under-indented for hanging indent", "            ])\n"], ["pycodestyle", "E121", 149, 4, "continuation line under-indented for hanging indent", "    )\n"], ["pycodestyle", "E126", 32, 16, "continuation line over-indented for hanging indent", "                'threshold'     : 0.1,    # delta unit threshold\n"], ["pycodestyle", "E126", 40, 16, "continuation line over-indented for hanging indent", "                **sdnn_params,                                 # copy all sdnn_params\n"], ["pycodestyle", "E126", 44, 16, "continuation line over-indented for hanging indent", "                **sdnn_cnn_params,                        # copy all sdnn_cnn_params\n"], ["pycodestyle", "E126", 49, 16, "continuation line over-indented for hanging indent", "                # delta encoding of the input\n"], ["pycodestyle", "E126", 143, 8, "continuation line over-indented for hanging indent", "        net=net,\n"], ["pycodestyle", "E203", 32, 31, "whitespace before ':'", "                'threshold'     : 0.1,    # delta unit threshold\n"], ["pycodestyle", "E203", 33, 31, "whitespace before ':'", "                'tau_grad'      : 0.5,    # delta unit surrogate gradient relaxation parameter\n"], ["pycodestyle", "E203", 34, 31, "whitespace before ':'", "                'scale_grad'    : 1,      # delta unit surrogate gradient scale parameter\n"], ["pycodestyle", "E203", 35, 31, "whitespace before ':'", "                'requires_grad' : True,   # trainable threshold\n"], ["pycodestyle", "E203", 36, 31, "whitespace before ':'", "                'shared_param'  : True,   # layer wise threshold\n"], ["pycodestyle", "E203", 37, 31, "whitespace before ':'", "                'activation'    : F.relu, # activation function\n"], ["pycodestyle", "E203", 41, 22, "whitespace before ':'", "                'norm' : slayer.neuron.norm.MeanOnlyBatchNorm, # mean only quantized batch normalizaton\n"], ["pycodestyle", "E203", 45, 25, "whitespace before ':'", "                'dropout' : slayer.neuron.Dropout(p=0.2), # neuron dropout\n"], ["pycodestyle", "E203", 111, 25, "whitespace before ','", "os.makedirs(logs_folder   , exist_ok=True)\n"], ["pycodestyle", "E203", 139, 45, "whitespace before ','", "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n"], ["pycodestyle", "E221", 101, 5, "multiple spaces before operator", "batch  = 8  # batch size\n"], ["pycodestyle", "E221", 102, 2, "multiple spaces before operator", "lr     = 0.001 # leaerning rate\n"], ["pycodestyle", "E221", 103, 3, "multiple spaces before operator", "lam    = 0.01  # lagrangian for event rate loss\n"], ["pycodestyle", "E221", 105, 5, "multiple spaces before operator", "steps  = [60, 120, 160] # learning rate reduction milestones\n"], ["pycodestyle", "E221", 139, 11, "multiple spaces before operator", "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n"], ["pycodestyle", "E225", 166, 15, "missing whitespace around operator", "    if epoch%50==49: print() \n"], ["pycodestyle", "E226", 59, 68, "missing whitespace around arithmetic operator", "                slayer.block.sigma_delta.Dense(sdnn_dense_params, 64*40, 100, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E226", 156, 35, "missing whitespace around arithmetic operator", "            param_group['lr'] /= 10/3\n"], ["pycodestyle", "E226", 190, 28, "missing whitespace around arithmetic operator", "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n"], ["pycodestyle", "E226", 190, 45, "missing whitespace around arithmetic operator", "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n"], ["pycodestyle", "E226", 190, 48, "missing whitespace around arithmetic operator", "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n"], ["pycodestyle", "E228", 166, 12, "missing whitespace around modulo operator", "    if epoch%50==49: print() \n"], ["pycodestyle", "E228", 176, 12, "missing whitespace around modulo operator", "    if epoch%10 == 0:\n"], ["pycodestyle", "E241", 52, 62, "multiple spaces after ','", "                slayer.block.sigma_delta.Conv(sdnn_cnn_params,  3, 24, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E241", 60, 65, "multiple spaces after ','", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,   100,  50, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E241", 60, 72, "multiple spaces after ','", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,   100,  50, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E241", 61, 65, "multiple spaces after ','", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,    50,  10, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E241", 61, 72, "multiple spaces after ','", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,    50,  10, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E241", 63, 66, "multiple spaces after ','", "                slayer.block.sigma_delta.Output(sdnn_dense_params,   10,   1, weight_scale=2, weight_norm=True)\n"], ["pycodestyle", "E241", 63, 72, "multiple spaces after ','", "                slayer.block.sigma_delta.Output(sdnn_dense_params,   10,   1, weight_scale=2, weight_norm=True)\n"], ["pycodestyle", "E261", 31, 23, "at least two spaces before inline comment", "        sdnn_params = { # sigma-delta neuron parameters\n"], ["pycodestyle", "E261", 37, 41, "at least two spaces before inline comment", "                'activation'    : F.relu, # activation function\n"], ["pycodestyle", "E261", 39, 27, "at least two spaces before inline comment", "        sdnn_cnn_params = { # conv layer has additional mean only batch norm\n"], ["pycodestyle", "E261", 41, 62, "at least two spaces before inline comment", "                'norm' : slayer.neuron.norm.MeanOnlyBatchNorm, # mean only quantized batch normalizaton\n"], ["pycodestyle", "E261", 43, 29, "at least two spaces before inline comment", "        sdnn_dense_params = { # dense layers have additional dropout units enabled\n"], ["pycodestyle", "E261", 45, 57, "at least two spaces before inline comment", "                'dropout' : slayer.neuron.Dropout(p=0.2), # neuron dropout\n"], ["pycodestyle", "E261", 48, 43, "at least two spaces before inline comment", "        self.blocks = torch.nn.ModuleList([# sequential network blocks \n"], ["pycodestyle", "E261", 102, 14, "at least two spaces before inline comment", "lr     = 0.001 # leaerning rate\n"], ["pycodestyle", "E261", 105, 23, "at least two spaces before inline comment", "steps  = [60, 120, 160] # learning rate reduction milestones\n"], ["pycodestyle", "E261", 158, 60, "at least two spaces before inline comment", "    for i, (input, ground_truth) in enumerate(train_loader): # training loop\n"], ["pycodestyle", "E261", 162, 59, "at least two spaces before inline comment", "    for i, (input, ground_truth) in enumerate(test_loader): # testing loop\n"], ["pycodestyle", "E261", 190, 73, "at least two spaces before inline comment", "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n"], ["pycodestyle", "E302", 22, 0, "expected 2 blank lines, found 1", "def event_rate_loss(x, max_rate=0.01):\n"], ["pycodestyle", "E302", 27, 0, "expected 2 blank lines, found 1", "class Network(torch.nn.Module):\n"], ["pycodestyle", "E303", 67, 4, "too many blank lines (2)", "    def forward(self, x):\n"], ["pycodestyle", "E303", 100, 0, "too many blank lines (3)", "# In [5]:\n"], ["pycodestyle", "E305", 101, 0, "expected 2 blank lines after class or function definition, found 3", "batch  = 8  # batch size\n"], ["pycodestyle", "E401", 3, 10, "multiple imports on one line", "import sys, os\n"], ["pycodestyle", "E501", 24, 80, "line too long (92 > 80 characters)", "    return F.mse_loss(F.relu(mean_event_rate - max_rate), torch.zeros_like(mean_event_rate))\n"], ["pycodestyle", "E501", 33, 80, "line too long (94 > 80 characters)", "                'tau_grad'      : 0.5,    # delta unit surrogate gradient relaxation parameter\n"], ["pycodestyle", "E501", 34, 80, "line too long (89 > 80 characters)", "                'scale_grad'    : 1,      # delta unit surrogate gradient scale parameter\n"], ["pycodestyle", "E501", 40, 80, "line too long (85 > 80 characters)", "                **sdnn_params,                                 # copy all sdnn_params\n"], ["pycodestyle", "E501", 41, 80, "line too long (103 > 80 characters)", "                'norm' : slayer.neuron.norm.MeanOnlyBatchNorm, # mean only quantized batch normalizaton\n"], ["pycodestyle", "E501", 43, 80, "line too long (82 > 80 characters)", "        sdnn_dense_params = { # dense layers have additional dropout units enabled\n"], ["pycodestyle", "E501", 44, 80, "line too long (84 > 80 characters)", "                **sdnn_cnn_params,                        # copy all sdnn_cnn_params\n"], ["pycodestyle", "E501", 52, 80, "line too long (129 > 80 characters)", "                slayer.block.sigma_delta.Conv(sdnn_cnn_params,  3, 24, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 53, 80, "line too long (129 > 80 characters)", "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 24, 36, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 54, 80, "line too long (139 > 80 characters)", "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 36, 64, 3, padding=(1, 0), stride=(2, 1), weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 55, 80, "line too long (129 > 80 characters)", "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 64, 64, 3, padding=0, stride=1, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 59, 80, "line too long (112 > 80 characters)", "                slayer.block.sigma_delta.Dense(sdnn_dense_params, 64*40, 100, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 60, 80, "line too long (112 > 80 characters)", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,   100,  50, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 61, 80, "line too long (112 > 80 characters)", "                slayer.block.sigma_delta.Dense(sdnn_dense_params,    50,  10, weight_scale=2, weight_norm=True),\n"], ["pycodestyle", "E501", 63, 80, "line too long (111 > 80 characters)", "                slayer.block.sigma_delta.Output(sdnn_dense_params,   10,   1, weight_scale=2, weight_norm=True)\n"], ["pycodestyle", "E501", 76, 80, "line too long (87 > 80 characters)", "                count.append(torch.sum(torch.abs((x[..., 1:]) > 0).to(x.dtype)).item())\n"], ["pycodestyle", "E501", 78, 80, "line too long (84 > 80 characters)", "        return x, event_cost, torch.FloatTensor(count).reshape((1, -1)).to(x.device)\n"], ["pycodestyle", "E501", 82, 80, "line too long (82 > 80 characters)", "        grad = [b.synapse.grad_norm for b in self.blocks if hasattr(b, 'synapse')]\n"], ["pycodestyle", "E501", 138, 80, "line too long (94 > 80 characters)", "train_loader = DataLoader(dataset=training_set, batch_size=batch, shuffle=True, num_workers=8)\n"], ["pycodestyle", "E501", 139, 80, "line too long (94 > 80 characters)", "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n"], ["pycodestyle", "E501", 144, 80, "line too long (84 > 80 characters)", "        error=lambda output, target: F.mse_loss(output.flatten(), target.flatten()),\n"], ["pycodestyle", "E501", 177, 80, "line too long (122 > 80 characters)", "        torch.save({'net': net.state_dict(), 'optimizer': optimizer.state_dict()}, logs_folder + f'/checkpoint{epoch}.pt')                   \n"], ["pycodestyle", "E501", 190, 80, "line too long (100 > 80 characters)", "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n"], ["pycodestyle", "E501", 192, 80, "line too long (100 > 80 characters)", "    print('\\rEvent count : ' + ', '.join([f'{c:.4f}' for c in count]), f'| {stats.testing}', end='') \n"], ["pycodestyle", "E701", 166, 19, "multiple statements on one line (colon)", "    if epoch%50==49: print() \n"], ["pycodestyle", "W291", 48, 70, "trailing whitespace", "        self.blocks = torch.nn.ModuleList([# sequential network blocks \n"], ["pycodestyle", "W291", 50, 60, "trailing whitespace", "                slayer.block.sigma_delta.Input(sdnn_params), \n"], ["pycodestyle", "W291", 71, 33, "trailing whitespace", "        for block in self.blocks: \n"], ["pycodestyle", "W291", 122, 15, "trailing whitespace", "    train=True, \n"], ["pycodestyle", "W291", 127, 7, "trailing whitespace", "    ]), \n"], ["pycodestyle", "W291", 130, 16, "trailing whitespace", "    train=False, \n"], ["pycodestyle", "W291", 154, 50, "trailing whitespace", "        for param_group in optimizer.param_groups:    \n"], ["pycodestyle", "W291", 166, 28, "trailing whitespace", "    if epoch%50==49: print() \n"], ["pycodestyle", "W291", 167, 31, "trailing whitespace", "    if stats.testing.best_loss:  \n"], ["pycodestyle", "W291", 177, 122, "trailing whitespace", "        torch.save({'net': net.state_dict(), 'optimizer': optimizer.state_dict()}, logs_folder + f'/checkpoint{epoch}.pt')                   \n"], ["pycodestyle", "W291", 191, 24, "trailing whitespace", "    counts.append(count) \n"], ["pycodestyle", "W291", 192, 100, "trailing whitespace", "    print('\\rEvent count : ' + ', '.join([f'{c:.4f}' for c in count]), f'| {stats.testing}', end='') \n"], ["pycodestyle", "W293", 30, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 47, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 65, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 66, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 90, 0, "blank line contains whitespace", "    \n"], ["pycodestyle", "W293", 97, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 98, 0, "blank line contains whitespace", "            \n"], ["pycodestyle", "W293", 157, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 161, 0, "blank line contains whitespace", "    \n"], ["pycodestyle", "W293", 165, 0, "blank line contains whitespace", "        \n"], ["pycodestyle", "W293", 171, 0, "blank line contains whitespace", "    \n"], ["pycodestyle", "W293", 174, 0, "blank line contains whitespace", "    \n"], ["pycodestyle", "W293", 193, 0, "blank line contains whitespace", "        \n"]], "digest": "8a9008fc5957ccfd40315767ec631590"}