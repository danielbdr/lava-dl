{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cf0164-9476-4f77-9c70-94663433a378",
   "metadata": {},
   "source": [
    "# Yolo-KP4: pruning Yolo-KP by 4x\n",
    "This tutorial demonstrates how to:\n",
    "- pre-train,\n",
    "- prune,\n",
    "- finetune\n",
    "  \n",
    "starting from the previously published Yolo-KP model in order to obtain **Yolo-KP4** improving on accuracy (+2.5%), memory footprint (4x smaller) and synaptic operations (4x smaller).\n",
    "\n",
    "Each step in the trainining is saved for easeness of use as torch network file.\n",
    "\n",
    "We finally run inference on Loihi2 provided the resources are set up. for this last point We will use yolo_kp/run.ipyb script  inference of YOLO-KP SDNN (training example scripts here) on both CPU and Loihi 2 neurocore.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17aad1e-dc14-457f-aded-3addcd250a37",
   "metadata": {},
   "source": [
    "### Pre-train the full model on MSCoco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01519e-8ab9-4d39-bc4c-34d01530380d",
   "metadata": {},
   "source": [
    "##### download or prepare the path for MSCOCO training set\n",
    "\n",
    "\n",
    "- we assume you have downloaded MSCooco dataset in path_DATASET. When running the script below add ensure to add *-path* path_DATASET to set the dataset path\n",
    "- Tune parameter *-b* according to the GPU RAM size available on your system. GPU splitting is not implemented explicitly.\n",
    "- Tune parameter *-num_workers* according to the number of available CPUs on your system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629025f9-8a8c-496f-8c76-2733a2b0c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /export/share/datasets/COCO2017\n",
      "KP/COCO//Trained_preTrain202405050720\n",
      "Using GPUs [0]\n",
      "Classes output: 80\n",
      "making net\n",
      "loading net on cuda:0\n",
      "module.init_model\n",
      "optimizer\n",
      "dataset\n",
      "loading annotations into memory...\n",
      "Done (t=13.82s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "yolo_loss\n",
      "stats\n",
      "loss_tracker\n",
      "train loop\n",
      "epoch:   0%|                                           | 0/1000 [00:00<?, ?it/s]\n",
      "Train: 0.0%|                                                            |0/9858 \u001b[A^C\n",
      "Exception ignored in: <function _releaseLock at 0x7f0dc5f43e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Training Yolo-KP model on COCO dataset \n",
    "## the following command should be run on an external terminal. Below is an example of running code - It was briefly (purpously interrupted) run here to show the correct setup and output.\n",
    "\n",
    "\n",
    "!python train_sdnnYolo.py -aug_prob 0.4 -b 12 -epoch 1000 -gpu 0 -lr 0.0005 -num_workers 24 -alpha_iou 0.8 -clip 1.0 -label_smoothing 0.03 -lambda_coord 2.0 -lambda_iou 2.25 -lambda_noobj 4.0 -lambda_obj 1.8  -lrf 0.01 -tgt_iou_thr 0.25 -track_iter 100 -warmup 40 -output_dir KP/COCO/ -strID preTrain -model single_head_KP -train -dataset COCO -threshold 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfef05-b7ed-413a-96b8-9d2d40c0467d",
   "metadata": {},
   "source": [
    "### Prune the KP model \n",
    "\n",
    "In the following we show how to load a preexisting torch weight file, we will then modify it by reducing the total size by 4x. \n",
    "The module accepts a \n",
    "\n",
    "*pruningFactor* = x which can be also a non integer. The result will be a 2*x reduction in size and compute.\n",
    "\n",
    "*pruningMethod* = {'random', 'L1', 'L2'}, for random pruning of the channels, or sorted along L1 or L2 norms and selecting *pruningFactor**(*# channels*) larger norms since they would contribute the most to the activity of the following layer.\n",
    "\n",
    "**NB** At this time we assume that the user will modify the former network config file/method to match the obtained weight size.\n",
    "Please refer to the module output for consistency matching. Future releases tackle the automatic creation of the config netowrk file after pruning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7d906f-5ac3-4064-ae02-b3944b84e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load path for libraries\n",
    "import torch\n",
    "import sys\n",
    "path = ['../YOLOsdnn/', '../.']\n",
    "sys.path.extend(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e1c61-b161-4043-988a-09fef0417cc5",
   "metadata": {},
   "source": [
    "##### CASE 1: when pruningFactor==2\n",
    "\n",
    "here below we prune a model for which the model config method was already created (*pruningFactor*=2):\n",
    "\n",
    "setting *logLevel*=2 the method will load the model script and test it against the resource evaluation routine:\n",
    "\n",
    "- you can prune the model trained at the previous cell by placing: <br />\n",
    "  ```saved_net_path = './KP/COCO/Trained_preTrain*DATE*/network.pt' ```\n",
    "- or alternatively, you can prune the pre-trained (maxed out) model as in the next cell\n",
    "\n",
    "the result will be saved in the same path of the provided *network.pt* file into a dedicated folder specifying pruning type and average pruning ratio per layer (point to this location for the following fine-tuning step)\n",
    "\n",
    "**NB** with the provided path for the pre-trained network you will obtain exactly the same starting model if using:  <br />\n",
    "  ```pruningMethod = 'random'```  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2270e35e-e4d4-4574-8308-3d9ed4c930b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors: [1, 3, 2] --> [1, 3, 2]\n",
      "input_blocks.0.neuron.bias: [1] --> [1]\n",
      "input_blocks.0.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.0.neuron.bias: [1] --> [1]\n",
      "blocks.0.neuron.norm.running_mean: [16] --> [8]\n",
      "blocks.0.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.0.synapse.weight_g: [16, 1, 1, 1, 1] --> [8, 1, 1, 1, 1]\n",
      "blocks.0.synapse.weight_v: [16, 3, 3, 3, 1] --> [8, 3, 3, 3, 1]\n",
      "blocks.1.neuron.bias: [1] --> [1]\n",
      "blocks.1.neuron.norm.running_mean: [32] --> [16]\n",
      "blocks.1.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.1.synapse.weight_g: [32, 1, 1, 1, 1] --> [16, 1, 1, 1, 1]\n",
      "blocks.1.synapse.weight_v: [32, 16, 3, 3, 1] --> [16, 8, 3, 3, 1]\n",
      "blocks.2.neuron.bias: [1] --> [1]\n",
      "blocks.2.neuron.norm.running_mean: [64] --> [32]\n",
      "blocks.2.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.2.synapse.weight_g: [64, 1, 1, 1, 1] --> [32, 1, 1, 1, 1]\n",
      "blocks.2.synapse.weight_v: [64, 32, 3, 3, 1] --> [32, 16, 3, 3, 1]\n",
      "blocks.3.neuron.bias: [1] --> [1]\n",
      "blocks.3.neuron.norm.running_mean: [128] --> [64]\n",
      "blocks.3.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.3.synapse.weight_g: [128, 1, 1, 1, 1] --> [64, 1, 1, 1, 1]\n",
      "blocks.3.synapse.weight_v: [128, 64, 3, 3, 1] --> [64, 32, 3, 3, 1]\n",
      "blocks.4.neuron.bias: [1] --> [1]\n",
      "blocks.4.neuron.norm.running_mean: [256] --> [128]\n",
      "blocks.4.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.4.synapse.weight_g: [256, 1, 1, 1, 1] --> [128, 1, 1, 1, 1]\n",
      "blocks.4.synapse.weight_v: [256, 128, 3, 3, 1] --> [128, 64, 3, 3, 1]\n",
      "blocks.5.neuron.bias: [1] --> [1]\n",
      "blocks.5.neuron.norm.running_mean: [256] --> [128]\n",
      "blocks.5.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.5.synapse.weight_g: [256, 1, 1, 1, 1] --> [128, 1, 1, 1, 1]\n",
      "blocks.5.synapse.weight_v: [256, 256, 3, 3, 1] --> [128, 128, 3, 3, 1]\n",
      "blocks.6.neuron.bias: [1] --> [1]\n",
      "blocks.6.neuron.norm.running_mean: [512] --> [256]\n",
      "blocks.6.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.6.synapse.weight_g: [512, 1, 1, 1, 1] --> [256, 1, 1, 1, 1]\n",
      "blocks.6.synapse.weight_v: [512, 256, 3, 3, 1] --> [256, 128, 3, 3, 1]\n",
      "blocks.7.neuron.bias: [1] --> [1]\n",
      "blocks.7.neuron.norm.running_mean: [256] --> [128]\n",
      "blocks.7.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.7.synapse.weight_g: [256, 1, 1, 1, 1] --> [128, 1, 1, 1, 1]\n",
      "blocks.7.synapse.weight_v: [256, 512, 1, 1, 1] --> [128, 256, 1, 1, 1]\n",
      "blocks.8.neuron.bias: [1] --> [1]\n",
      "blocks.8.neuron.norm.running_mean: [512] --> [256]\n",
      "blocks.8.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.8.synapse.weight_g: [512, 1, 1, 1, 1] --> [256, 1, 1, 1, 1]\n",
      "blocks.8.synapse.weight_v: [512, 256, 3, 3, 1] --> [256, 128, 3, 3, 1]\n",
      "heads.0.weight: [255, 512, 1, 1, 1] --> [255, 256, 1, 1, 1]\n",
      "saving to ./Pruning/trainedModels/Yolo_KP/L1_pruning_by2.0/network.pt\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Network                                       [1, 42, 85, 448]          --\n",
      "├─ModuleList: 1-1                             --                        --\n",
      "│    └─Input: 2-1                             [1, 3, 3, 448, 448]       --\n",
      "│    │    └─Neuron: 3-1                       --                        (2)\n",
      "├─ModuleList: 1-2                             --                        --\n",
      "│    └─Conv: 2-2                              [1, 8, 2, 224, 448]       --\n",
      "│    │    └─Conv: 3-2                         [1, 8, 2, 224, 448]       224\n",
      "│    │    └─Neuron: 3-3                       [1, 8, 2, 224, 448]       (2)\n",
      "│    └─Conv: 2-3                              [1, 16, 1, 112, 448]      --\n",
      "│    │    └─Conv: 3-4                         [1, 16, 1, 112, 448]      1,168\n",
      "│    │    └─Neuron: 3-5                       [1, 16, 1, 112, 448]      (2)\n",
      "│    └─Conv: 2-4                              [1, 32, 1, 56, 448]       --\n",
      "│    │    └─Conv: 3-6                         [1, 32, 1, 56, 448]       4,640\n",
      "│    │    └─Neuron: 3-7                       [1, 32, 1, 56, 448]       (2)\n",
      "│    └─Conv: 2-5                              [1, 64, 1, 28, 448]       --\n",
      "│    │    └─Conv: 3-8                         [1, 64, 1, 28, 448]       18,496\n",
      "│    │    └─Neuron: 3-9                       [1, 64, 1, 28, 448]       (2)\n",
      "│    └─Conv: 2-6                              [1, 128, 1, 28, 448]      --\n",
      "│    │    └─Conv: 3-10                        [1, 128, 1, 28, 448]      73,856\n",
      "│    │    └─Neuron: 3-11                      [1, 128, 1, 28, 448]      (2)\n",
      "│    └─Conv: 2-7                              [1, 128, 1, 14, 448]      --\n",
      "│    │    └─Conv: 3-12                        [1, 128, 1, 14, 448]      147,584\n",
      "│    │    └─Neuron: 3-13                      [1, 128, 1, 14, 448]      (2)\n",
      "│    └─Conv: 2-8                              [1, 256, 1, 14, 448]      --\n",
      "│    │    └─Conv: 3-14                        [1, 256, 1, 14, 448]      295,168\n",
      "│    │    └─Neuron: 3-15                      [1, 256, 1, 14, 448]      (2)\n",
      "│    └─Conv: 2-9                              [1, 128, 1, 14, 448]      --\n",
      "│    │    └─Conv: 3-16                        [1, 128, 1, 14, 448]      32,896\n",
      "│    │    └─Neuron: 3-17                      [1, 128, 1, 14, 448]      (2)\n",
      "│    └─Conv: 2-10                             [1, 256, 1, 14, 448]      --\n",
      "│    │    └─Conv: 3-18                        [1, 256, 1, 14, 448]      295,168\n",
      "│    │    └─Neuron: 3-19                      [1, 256, 1, 14, 448]      (2)\n",
      "├─ModuleList: 1-3                             --                        --\n",
      "│    └─Conv: 2-11                             [1, 255, 1, 14, 448]      65,280\n",
      "│    └─Sigma: 2-12                            [1, 255, 1, 14, 448]      --\n",
      "===============================================================================================\n",
      "Total params: 934,500\n",
      "Trainable params: 934,480\n",
      "Non-trainable params: 20\n",
      "Total mult-adds (M): 594.47\n",
      "===============================================================================================\n",
      "Input size (MB): 2.41\n",
      "Forward/backward pass size (MB): 194.23\n",
      "Params size (MB): 3.74\n",
      "Estimated Total Size (MB): 200.38\n",
      "===============================================================================================\n",
      "succesfull pruning!\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from combined_heads import networkPruning\n",
    "## prune the pre-trained model saved in the following path\n",
    "networkPruning('./Pruning/trainedModels/Yolo_KP/network.pt', logLevel=2, pruningMethod='random', pruningFactor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7421e-041b-43cc-b3a5-89e8519a3824",
   "metadata": {},
   "source": [
    "#### Case 2: when pruningFactor!=2\n",
    "Here another example when *pruningFactor*!=2 - set ```logLevel = 1``` and manually define/modify a network model using ```models/short_*.py``` as a template, setting layer dimensions along the following output that indicates where to make the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b80cee58-5055-44fd-9b21-888921306e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors: [1, 3, 2] --> [1, 3, 2]\n",
      "input_blocks.0.neuron.bias: [1] --> [1]\n",
      "input_blocks.0.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.0.neuron.bias: [1] --> [1]\n",
      "blocks.0.neuron.norm.running_mean: [8] --> [3]\n",
      "blocks.0.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.0.synapse.weight_g: [8, 1, 1, 1, 1] --> [3, 1, 1, 1, 1]\n",
      "blocks.0.synapse.weight_v: [8, 3, 3, 3, 1] --> [3, 3, 3, 3, 1]\n",
      "blocks.1.neuron.bias: [1] --> [1]\n",
      "blocks.1.neuron.norm.running_mean: [16] --> [6]\n",
      "blocks.1.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.1.synapse.weight_g: [16, 1, 1, 1, 1] --> [6, 1, 1, 1, 1]\n",
      "blocks.1.synapse.weight_v: [16, 8, 3, 3, 1] --> [6, 3, 3, 3, 1]\n",
      "blocks.2.neuron.bias: [1] --> [1]\n",
      "blocks.2.neuron.norm.running_mean: [32] --> [11]\n",
      "blocks.2.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.2.synapse.weight_g: [32, 1, 1, 1, 1] --> [11, 1, 1, 1, 1]\n",
      "blocks.2.synapse.weight_v: [32, 16, 3, 3, 1] --> [11, 6, 3, 3, 1]\n",
      "blocks.3.neuron.bias: [1] --> [1]\n",
      "blocks.3.neuron.norm.running_mean: [64] --> [22]\n",
      "blocks.3.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.3.synapse.weight_g: [64, 1, 1, 1, 1] --> [22, 1, 1, 1, 1]\n",
      "blocks.3.synapse.weight_v: [64, 32, 3, 3, 1] --> [22, 11, 3, 3, 1]\n",
      "blocks.4.neuron.bias: [1] --> [1]\n",
      "blocks.4.neuron.norm.running_mean: [128] --> [43]\n",
      "blocks.4.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.4.synapse.weight_g: [128, 1, 1, 1, 1] --> [43, 1, 1, 1, 1]\n",
      "blocks.4.synapse.weight_v: [128, 64, 3, 3, 1] --> [43, 22, 3, 3, 1]\n",
      "blocks.5.neuron.bias: [1] --> [1]\n",
      "blocks.5.neuron.norm.running_mean: [128] --> [43]\n",
      "blocks.5.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.5.synapse.weight_g: [128, 1, 1, 1, 1] --> [43, 1, 1, 1, 1]\n",
      "blocks.5.synapse.weight_v: [128, 128, 3, 3, 1] --> [43, 43, 3, 3, 1]\n",
      "blocks.6.neuron.bias: [1] --> [1]\n",
      "blocks.6.neuron.norm.running_mean: [256] --> [86]\n",
      "blocks.6.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.6.synapse.weight_g: [256, 1, 1, 1, 1] --> [86, 1, 1, 1, 1]\n",
      "blocks.6.synapse.weight_v: [256, 128, 3, 3, 1] --> [86, 43, 3, 3, 1]\n",
      "blocks.7.neuron.bias: [1] --> [1]\n",
      "blocks.7.neuron.norm.running_mean: [128] --> [43]\n",
      "blocks.7.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.7.synapse.weight_g: [128, 1, 1, 1, 1] --> [43, 1, 1, 1, 1]\n",
      "blocks.7.synapse.weight_v: [128, 256, 1, 1, 1] --> [43, 86, 1, 1, 1]\n",
      "blocks.8.neuron.bias: [1] --> [1]\n",
      "blocks.8.neuron.norm.running_mean: [256] --> [86]\n",
      "blocks.8.neuron.delta.threshold: [1] --> [1]\n",
      "blocks.8.synapse.weight_g: [256, 1, 1, 1, 1] --> [86, 1, 1, 1, 1]\n",
      "blocks.8.synapse.weight_v: [256, 128, 3, 3, 1] --> [86, 43, 3, 3, 1]\n",
      "heads.0.weight: [48, 256, 1, 1, 1] --> [48, 86, 1, 1, 1]\n",
      "saving to ./trainedModels/Yolo_KP4/L1_pruning_by1.5/network.pt\n",
      "Model parameter heads.0.weight was not loaded.\n",
      "succesfull pruning!\n"
     ]
    }
   ],
   "source": [
    "# Example showing pruning on different pruiningMethod and pruningFactor\n",
    "\n",
    "networkPruning('./trainedModels/Yolo_KP4/network.pt', logLevel=1, pruningMethod='L1', pruningFactor=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e29de-2414-4aa7-9cf2-9f9ec832d698",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "\n",
    "You can skip this step if you want to use the pre-trained fine-tuned network stored in *./Pruning/trainedModels/Yolo_KP4/network.pt*\n",
    "\n",
    "With the pruned network obtained earlier and after having setup BDD100K dataset in *dataset_path* add the also *-dataset_path dataset_path* when invoking the following command\n",
    "\n",
    "You will notice that the model once loaded discards the output layer as it was pretrained on COCO that has 80 output classes. BDD100K has 11 output classes. The two models will mostly share the rest of the topology but for the output layer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ff5b09-ea72-471e-8001-88191aaf2677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /export/share/datasets/BDD100K/MOT2020/bdd100k\n",
      "KP4/BDD//Trained_fineTuned202405051100\n",
      "Using GPUs [0]\n",
      "Classes output: 11\n",
      "making net\n",
      "loading net on cuda:0\n",
      "Initializing model from ./Pruning/trainedModels/Yolo_KP/random_pruning_by2.0/network.pt\n",
      "Model parameter heads.0.weight was not loaded.\n",
      "module.init_model\n",
      "optimizer\n",
      "dataset\n",
      "yolo_loss\n",
      "stats\n",
      "loss_tracker\n",
      "train loop\n",
      "epoch:   0%|                                            | 0/800 [00:00<?, ?it/s]\n",
      "Train: 0.0%|                                                             |0/117 \u001b[A\n",
      "epoch:   0%|                | 0/800 [02:19<?, ?it/s, |Trn:0.015 |Rate:0.16±0.14]\u001b[A\n",
      "Train: 0.9%| |1/117 , Rate: [0.21, 0.09, 0.08, 0.08, 0.09, 0.10, 0.11, 0.11, 0.0\u001b[A^C\n",
      "\n",
      "epoch:   0%|                | 0/800 [02:27<?, ?it/s, |Trn:0.015 |Rate:0.16±0.14]\u001b[A\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dbendaya/_work_/ContinualLearning/tinyYolov3_lava/YOLOsdnn/yoloKP4/train_sdnnYolo.py\", line 317, in <module>\n",
      "    for i, (inputs, targets, bboxes) in enumerate(pbar):\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/queue.py\", line 180, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/home/dbendaya/.venv/lib/python3.10/threading.py\", line 324, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Yolo-KP4 model on BDD100K dataset \n",
    "## the following command should be run on an external terminal. Below is an example of running code - It was briefly (purpously interrupted) run here to show the correct setup and output.\n",
    "\n",
    "!python train_sdnnYolo.py -aug_prob 0.4 -b 12 -epoch 800 -gpu 0 -lr 0.0005 -num_workers 24 -alpha_iou 0.8 -clip 1.0 -label_smoothing 0.03 -lambda_coord 2.0 -lambda_iou 2.25 -lambda_noobj 4.0 -lambda_obj 1.8  -lrf 0.01 -tgt_iou_thr 0.25 -track_iter 100 -warmup 40 -output_dir KP4/BDD/ -strID fineTuned -model short_single_head_KP -train -dataset BDD100K -threshold 0.1 -load ./Pruning/trainedModels/Yolo_KP/random_pruning_by2.0/network.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6163f-c199-4c9f-bc07-6c10b2bdd32f",
   "metadata": {},
   "source": [
    "### inference\n",
    "\n",
    "you can run inference using exactly the commands reported earlier by omitting the parameter *-train*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
